{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42bf890a-04bc-4888-8e21-385ff14a4011",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark=SparkSession.builder.appName('File_Validation').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f3bfdd4-af4a-4220-be5c-f5d7ea017725",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv is not empty\n+-------+------------------+--------------+--------------+---------+---------+--------------------+----------+-----+------------------+\n|summary|       customer_id|customer_fname|customer_lname| username| password|             address|      city|state|           pincode|\n+-------+------------------+--------------+--------------+---------+---------+--------------------+----------+-----+------------------+\n|  count|             12435|         12435|         12435|    12435|    12435|               12435|     12435|12435|             12435|\n|   mean|            6218.0|          null|          null|     null|     null|                null|      null| null|36043.661680739846|\n| stddev|3589.8196333520714|          null|          null|     null|     null|                null|      null| null| 37623.00199497027|\n|    min|                 1|         Aaron|        Abbott|XXXXXXXXX|XXXXXXXXX|      1 Bright Manor| Aguadilla|   AL|             00603|\n|    max|              9999|       Zachary|        Zuniga|XXXXXXXXX|XXXXXXXXX|9995 Tawny Embers...|Zanesville|   WV|             99205|\n+-------+------------------+--------------+--------------+---------+---------+--------------------+----------+-----+------------------+\n\nNumber of duplicate rows: 0\ncustomer_id:12435 distinct values\ncustomer_fname:200 distinct values\ncustomer_lname:985 distinct values\nusername:1 distinct values\npassword:1 distinct values\naddress:6943 distinct values\ncity:562 distinct values\nstate:44 distinct values\npincode:1000 distinct values\nNo Schema Mismatch\nshow correlation\nconsistent data\n+-----------+--------------+--------------+---------+---------+--------------------+-------------+-----+-------+\n|customer_id|customer_fname|customer_lname| username| password|             address|         city|state|pincode|\n+-----------+--------------+--------------+---------+---------+--------------------+-------------+-----+-------+\n|          1|       Richard|     Hernandez|XXXXXXXXX|XXXXXXXXX|  6303 Heather Plaza|  Brownsville|   TX|  78521|\n|          2|          Mary|       Barrett|XXXXXXXXX|XXXXXXXXX|9526 Noble Embers...|    Littleton|   CO|  80126|\n|          3|           Ann|         Smith|XXXXXXXXX|XXXXXXXXX|3422 Blue Pioneer...|       Caguas|   PR|  00725|\n|          4|          Mary|         Jones|XXXXXXXXX|XXXXXXXXX|  8324 Little Common|   San Marcos|   CA|  92069|\n|          5|        Robert|        Hudson|XXXXXXXXX|XXXXXXXXX|10 Crystal River ...|       Caguas|   PR|  00725|\n|          6|          Mary|         Smith|XXXXXXXXX|XXXXXXXXX|3151 Sleepy Quail...|      Passaic|   NJ|  07055|\n|          7|       Melissa|        Wilcox|XXXXXXXXX|XXXXXXXXX|9453 High Concession|       Caguas|   PR|  00725|\n|          8|         Megan|         Smith|XXXXXXXXX|XXXXXXXXX|3047 Foggy Forest...|     Lawrence|   MA|  01841|\n|          9|          Mary|         Perez|XXXXXXXXX|XXXXXXXXX| 3616 Quaking Street|       Caguas|   PR|  00725|\n|         10|       Melissa|         Smith|XXXXXXXXX|XXXXXXXXX|8598 Harvest Beac...|     Stafford|   VA|  22554|\n|         11|          Mary|       Huffman|XXXXXXXXX|XXXXXXXXX|    3169 Stony Woods|       Caguas|   PR|  00725|\n|         12|   Christopher|         Smith|XXXXXXXXX|XXXXXXXXX|5594 Jagged Ember...|  San Antonio|   TX|  78227|\n|         13|          Mary|       Baldwin|XXXXXXXXX|XXXXXXXXX|7922 Iron Oak Gar...|       Caguas|   PR|  00725|\n|         14|     Katherine|         Smith|XXXXXXXXX|XXXXXXXXX|5666 Hazy Pony Sq...|  Pico Rivera|   CA|  90660|\n|         15|          Jane|          Luna|XXXXXXXXX|XXXXXXXXX|    673 Burning Glen|      Fontana|   CA|  92336|\n|         16|       Tiffany|         Smith|XXXXXXXXX|XXXXXXXXX|      6651 Iron Port|       Caguas|   PR|  00725|\n|         17|          Mary|      Robinson|XXXXXXXXX|XXXXXXXXX|     1325 Noble Pike|       Taylor|   MI|  48180|\n|         18|        Robert|         Smith|XXXXXXXXX|XXXXXXXXX|2734 Hazy Butterf...|     Martinez|   CA|  94553|\n|         19|     Stephanie|      Mitchell|XXXXXXXXX|XXXXXXXXX|3543 Red Treasure...|       Caguas|   PR|  00725|\n|         20|          Mary|         Ellis|XXXXXXXXX|XXXXXXXXX|      4703 Old Route|West New York|   NJ|  07093|\n+-----------+--------------+--------------+---------+---------+--------------------+-------------+-----+-------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path=\"dbfs:/FileStore/customers1.csv\"  \n",
    "file_type=\"csv\"\n",
    "expected_schema=[\"customer_id\",\"customer_fname\",\"customer_lname\",\"username\",\"password\",\"address\",\"city\",\"state\",\"pincode\"]\n",
    "\n",
    "def duplicate():\n",
    "    duplicate_rows=df.count()-df.dropDuplicates().count()\n",
    "    print(f'Number of duplicate rows: {duplicate_rows}')\n",
    "    df.dropDuplicates()\n",
    "    return df\n",
    "\n",
    "def dictinct_count():\n",
    "    for column in df.columns:\n",
    "        print(f'{column}:{df.select(column).distinct().count()} distinct values')\n",
    "    return df\n",
    "\n",
    "def count_null():\n",
    "    df.select(*(sum(col(c).isNull().cast(\"int\")).alias(c)for c in df.columns))\n",
    "    return df\n",
    "\n",
    "def schema_mismatch():\n",
    "    if not all(col in df.columns for col in expected_schema):\n",
    "        print(\"schema_mismatch\")\n",
    "    else:\n",
    "        print(\"No Schema Mismatch\")\n",
    "    return df\n",
    "\n",
    "def correlation():\n",
    "    df.select(corr(\"pincode\",\"address\"))\n",
    "    print(f'show correlation')\n",
    "    return df\n",
    "\n",
    "def dependency_chk():\n",
    "    if df.filter(df.customer_fname.isNull() & df.customer_lname.isNotNull()):\n",
    "        print(f'consistent data')\n",
    "    else:\n",
    "        print(f'inconsistent data')\n",
    "    return df\n",
    "\n",
    "def read_file():\n",
    "    df=spark.read.format(file_type).option(\"header\", \"true\").load(file_path)\n",
    "    if df.count()==0: \n",
    "        print(file_type + \" is empty\")\n",
    "    else:\n",
    "        print(file_type + \" is not empty\")\n",
    "        df.describe().show()\n",
    "        duplicate()\n",
    "        dictinct_count()\n",
    "        count_null()\n",
    "        schema_mismatch()\n",
    "        correlation()\n",
    "        dependency_chk().show()\n",
    "    return df    \n",
    "\n",
    "df=read_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc5b7836-4ca5-493f-b2ee-7f3e9039111f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Python_File_Validation_Script",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
